import time
from langchain.document_loaders import UnstructuredFileLoader
from langchain.storage import LocalFileStore
from langchain.text_splitter import CharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings
from langchain.vectorstores.faiss import FAISS
from pydantic import FilePath
import streamlit as st

st.set_page_config(
    page_title="DocumentGPT",
    page_icon="ğŸ“ƒ",
)


# Embedding Method
def embed_file(file):
    # file ì½ê¸°
    file_content = file.read()
    # st.write(file_content)
    # file path ê²°ì •
    file_path = f"./.cache/files/{file.name}"
    # st.write(file_path)
    # file_pathì— w(rite)b(inary) ëª¨ë“œë¡œ ì—´ê¸°
    with open(file_path, "wb") as f:
        # file ë‚´ìš©ì„ ê¸°ë¡
        f.write(file_content)
    # cache directory ì„¤ì •: ë¡œì»¬ì— íŒŒì¼ ì €ì¥
    cache_dir = LocalFileStore(f"./.cache/embeddings/{file.name}")
    splitter = CharacterTextSplitter.from_tiktoken_encoder(
        separator="\n",
        chunk_size=600,
        chunk_overlap=100,
    )
    # íŒŒì¼ ë¡œë”
    loader = UnstructuredFileLoader(file_path)
    # ìª¼ê°  ë¬¸ì„œë“¤ì„ docs ë¦¬ìŠ¤íŠ¸ì— ë„£ì–´ë‘ . load_and_splitì€ List of docs ë°˜í™˜
    docs = loader.load_and_split(text_splitter=splitter)
    # OpenAIEmbeddings ë©”ì†Œë“œ ì‚¬ìš©
    embeddings = OpenAIEmbeddings()
    # ìºì‹œì— ì„ë² ë”©í•˜ì—¬ ì´ë¯¸ ìºì‹œë˜ì–´ ìˆëŠ” ê²½ìš° ì‘ì—…ì„ ìƒëµ. ì—†ìœ¼ë©´ ì„ë² ë”©.
    cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)
    # FAISS Vector Storeë¥¼ ì´ìš©í•˜ì—¬ ë¬¸ì„œë¥¼ ë²¡í„°ë¡œ ì €ì¥
    vectorstore = FAISS.from_documents(docs, cached_embeddings)
    # Vectorstoreì— ì €ì¥ëœ ê°’ì„ Retrieverë¡œ ë³€í™˜
    retriever = vectorstore.as_retriever()
    # retrieverì—ê²Œ invokeí•˜ëŠ” ê²ƒì€ ë¬¸ì„œì—ì„œ í•´ë‹¹ ë‚´ìš©ì„ ê²€ìƒ‰í•˜ì—¬ ê²°ê³¼ë¥¼ List of relavant docsë¡œ ë°˜í™˜
    # docs = retriever.invoke("ministry of truth")
    # st.write(docs) # í™•ì¸
    return retriever


# messageë¥¼ í™”ë©´ì— ë³´ì—¬ì£¼ê³ , session_stateì— ì €ì¥í•˜ì—¬ ë³´ê´€
def send_message(message, role, save=True):
    with st.chat_message(role):
        st.markdown(message)
    if save:
        st.session_state["messages"].append({"message": message, "role": role})


# session_stateì— ì €ì¥ëœ ë©”ì‹œì§€ë¥¼ í™”ë©´ì— ë³´ì—¬ì¤Œ, ì €ì¥ì€ ë¹„í™œì„±í™”
# ì €ì¥ì„ í•˜ëŠ” ê²½ìš° ì¤‘ë³µ ì €ì¥ë¨
def paint_history():
    for message in st.session_state["messages"]:
        send_message(
            message["message"],
            message["role"],
            save=False,
        )


st.title("DocumentGPT")

st.markdown(
    """
Welcome!
            
Use this chatbot to ask questions to an AI about your files!

Upload your file on the sidebar.
"""
)

# íŒŒì¼ ì…ë ¥ ì°½ì„ ì‚¬ì´ë“œë°”ë¡œ ì´ë™
with st.sidebar:
    file = st.file_uploader(
        "Upload a .txt .pdf or .docx file",
        type=["pdf", "txt", "docx"],
    )

# íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¨ ê²½ìš° ì„ë² ë”©í•˜ê³ , ì„ë² ë”©ì´ ì™„ë£Œë˜ë©´ ì¤€ë¹„ì™„ë£Œ ë©”ì‹œì§€ë¥¼ ë³´ëƒ„
# aiê°€ ì¤€ë¹„ì™„ë£ŒëìŒì„ ë‚˜íƒ€ë‚´ëŠ” ë©”ì‹œì§€ëŠ” ì €ì¥í•  í•„ìš” ì—†ìŒ
if file:
    retriever = embed_file(file)
    send_message("I'm ready! Ask away!", "ai", save=False)
    # í™”ë©´ì— ì €ì¥ëœ ë©”ì‹œì§€ë¥¼ ë³´ì—¬ì¤Œ
    paint_history()
    # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë©”ì‹œì§€ë¥¼ ë³´ì—¬ì£¼ê³  ì €ì¥í•¨
    message = st.chat_input("Ask anything about your file...")
    if message:
        send_message(message, "human")
else:
    # íŒŒì¼ì´ ì—†ê±°ë‚˜ ì—†ì–´ì§€ëŠ” ê²½ìš° session_stateë¥¼ ì´ˆê¸°í™”
    st.session_state["messages"] = []
